はじめまして。チームみらい 永田町エンジニアチームの伊藤と申します。

先日チームみらいでは、政治資金の流れを透明性を持って公開するプラットフォーム「みらい まる見え政治資金」をリリースし、またソースコードを OSS として公開し、大きな反響をいただきました。

なぜチームみらいがこのサービスを公開するのかについては別の記事に譲るとして、この記事では、ソフトウェアエンジニア向けに振り切った記事として、サービス構成と、実装を支えたLLM活用についてご紹介したいと思います。

このサービスは、現時点でコード量としては約 15,000 行と、「中規模」くらいのアプリケーションと言えるかなと思いますが、（しっかり測ったわけではないですが）少なく見積もってもコードの 95%以上はLLMによって書かれています。

といっても、AIに丸投げしてもこのようなサービスがうまく構築されていくわけではありません。AIがコーディング作業を適切に進められるように、設計・作業指示・レビューを人間が丁寧に行うことで、この規模のサービスを大きな不具合なく構築することができたと考えています。

みらい まる見え政治資金とは

政治とカネ問題を、モラルではなく仕組みで解決するツール

(サービスのスクショを入れる)

「みらい まる見え政治資金」は、安野貴博の参議院初登庁後、100日以内の実現を公約する「100日プラン」の一つとして、有権者の皆さまと約束して構築されたサービスです。

現在の政治資金報告書は、年に一度、紙やPDFで公開されます。複雑な勘定科目と専門用語が並び、一般市民はもちろん、当の政治家本人ですら「全体でいくら使ったのか」「今月はいくら残っているのか」を把握しづらい構造になっています。

このサービスは、クラウド会計ソフト（MFクラウド・freee等）に記帳した会計データを、年に一度ではなく随時Webダッシュボードとして公開します。

議員本人は「今月いくら使ったか」を毎日確認できます。事務担当者は複雑な政治資金報告書を、クラウド会計から短時間で作成できます。そして市民は、政党のカネの流れをリアルタイムでモニタリングし、1件1件の支出の妥当性を検証できます。

OSSで公開することで、より広い問題解決を目指す

また、このサービスのソースコードは、AGPL-3.0ライセンスでOSS公開されています。

サービス構成

では、ここからは技術スタックとサービスの構成についてご紹介していきます。構成図は下記の通り。DB層としてSupabase（Postgres）を使い、ユーザー画面と管理画面を、それぞれ異なるvercel環境でホスティングしています。

技術選定理由

永田町エンジニアチームとして、以下のような観点から技術選定を行いました。

vercel

選定した理由は、特別な設定無しにSEOに適した構成を作りやすいことです。デフォルトの状態でサーバーコンポーネントやSSRが活用でき、また簡潔な記述でキャッシュ設定もできる点から、リッチなUIを実現しつつ検索エンジンからの流入を見込めるサイトを短期間で実装するのに適していると判断しました。また、ブランチごとに実行環境が用意される機能は、Devinなどリモート型のコーディングAIに任せた機能のデバッグに役立ちました。

supabase

選定した理由は、スピード感とロックイン性の低さです。mBaaSとして、ほとんど設定無しにデータベースをブランチ単位で用意できることが短期間の開発においては大きな魅力となりました。また、代替技術の少ない、firebaseのようなドキュメント志向DBと比較し、supabaseは伝統的なRDBであるPostgresが標準であり、別の環境へのポート可能性が高いと考えました。

そのうえで、データベースへのアクセスを行うRepository層は必ずInterfaceを噛ませることをルールとし、MySQL環境などへの移行も問題なく実現できるように注意しています。

高速化・最適化戦略

政治資金データは、それほど頻繁に更新されるものではなく、更新から反映までのタイムラグがあっても問題が起きにくい性質の情報なので、キャッシュが有効です。

まる見え政治資金では、基本的に利用されてほしいキャッシュとしてページ単位でのキャッシュを5分間有効にしつつ、ページ単位でのキャッシュが効いていないケースに備え、念の為でバックエンドでも1分単位のキャッシュを生成しています。

データ取得は極力サーバー処理に

また、エンドユーザーが触れる画面においては、ページごとに全てのデータ取得を一つのサーバー関数にまとめ、そこから書くコンポーネントにデータを渡す設計にすることで、クライアントサイドでのデータフェッチをゼロにし、端末性能に依存しない描画速度を実現しています。

PageSpeed Insight

その結果、Google Pagespeed Insightではパフォーマンスで安定して80点前後が出るような描画速度を実現できています。

LLM に 95%を任せるための工夫

このプロジェクトでは、コードベース約15000行のうち、体感95%以上をLLM（Claude Code）に書かせることができました。ただし、これは単なる「丸投げ」ではありません。設計とレビューは人間が担当し、バグや悪い設計を生まないための仕組みを徹底的に作り込んでいます。

以下、その具体的な工夫を紹介します。

工夫 ①: CLAUDE.md で常に重要事項を意識させる

LLMに開発を任せる上で最も重要なのは、プロジェクト全体のルールを常に意識させることです。そのために、私たちは `CLAUDE.md` というファイルをリポジトリのルートに配置し、Claude Codeがファイル操作をする際に自動的に参照されるようにしています。

CLAUDE.mdには以下のような内容を記載しています：

設計作業ルール: 設計ドキュメントのファイル名規則や保存場所

Next.js実装ルール: サーバーコンポーネントとクライアントコンポーネントの使い分け、データ取得パターン

コード構成: ディレクトリ構造と各ディレクトリの責務

GitHub操作ルール: ブランチ戦略、PR作成時の注意事項、デプロイ前のチェック項目

例えば、Next.jsの実装ルールでは以下のように明記しています：

- データ取得はなるべくサーバーコンポーネントに寄せる- サーバー側で動作することを期待する処理には import "server-only" を書き、誤ってクライアントから参照されないようにする- サーバーアクション（"use server"処理）は、データ更新やファイルアップロードなど副作用を伴う操作のためだけに使い、あわせて revalidatePath や revalidateTag などの再検証処理までを1セットで行う

このように具体的なルールを書いておくことで、LLMが一貫性のあるコードを生成できるようになります。人間同士の開発でも「コーディング規約」は重要ですが、LLMに対してはさらに効果的です。曖昧さを排除し、明確な指示を与えることが成功の鍵です。

工夫 ②: 設計ドキュメントを先に作らせる

複雑な機能を実装する際、いきなりコードを書き始めるとLLMが迷走したり、手戻りが大きくなったりしがちです。そこで複雑性の高い機能には、以下のように段階を踏ませることで、手戻りを最小限にする工夫をしています。

設計フェーズ: `docs/` 以下にマークダウンで機能概要ドキュメントを作成させる

レビューフェーズ: 人間が設計ドキュメントをレビューし、フィードバックする

実装フェーズ: 承認された設計に基づいてコードを実装させる

特に、大量のコンテキストを必要とする機能（例：データのインポート処理、複雑な集計ロジックなど）では、この方法が非常に有効でした。

また、定期的にリポジトリ構成を「第三者的な視点」でLLMにレビューしてもらうことも行っています。例えば：

「現在のリポジトリ構成を確認して、クリーンアーキテクチャの原則から逸脱している部分がないか指摘してください」

このように問いかけることで、設計の崩れを早期に発見し、修正できます。

工夫 ③: LLM が混乱しにくいアーキテクチャ

LLMにコードを書かせる上で、責務が明確に分離されたアーキテクチャは極めて重要です。人間であれば「このくらいまとめて書いてしまおう」と省略したくなる部分も、LLMには厳格なレイヤー構造を守らせることで、むしろ品質が向上します。

まる見え政治資金のアーキテクチャ

クリーンアーキテクチャベースのファイル設計

私たちは以下のようなレイヤー構造を採用しています：

server/
├── loaders/        # エントリーポイント（参照系）
├── actions/        # エントリーポイント（書き込み系）
├── usecases/       # ビジネスロジックの組み立て
├── lib/            # データ加工・変換処理
├── repositories/   # データアクセス層
└── auth/           # 認証関連処理

BFFパターンの採用

各ページに対して、単一のloader（例：`load-top-page-data.ts`）を用意し、そのloaderが複数のusecaseを並列実行します。以下は実際のコード例です：

export const loadTopPageData = unstable_cache(
  async (params: TopPageDataParams) => {
    // Repositoryの初期化
    const transactionRepository = new PrismaTransactionRepository(prisma);
    const politicalOrganizationRepository = new PrismaPoliticalOrganizationRepository(prisma);
    const balanceSnapshotRepository = new PrismaBalanceSnapshotRepository(prisma);

    // Usecaseの初期化
    const transactionUsecase = new GetTransactionsBySlugUsecase(
      transactionRepository,
      politicalOrganizationRepository,
    );
    const monthlyUsecase = new GetMonthlyTransactionAggregationUsecase(
      transactionRepository,
      politicalOrganizationRepository,
    );
    // ... 他のusecaseも同様に初期化

    // 並列実行
    const [transactionData, monthlyData, sankeyData, balanceSheetData] =
      await Promise.all([
        transactionUsecase.execute(params),
        monthlyUsecase.execute(params),
        sankeyUsecase.execute(params),
        balanceSheetUsecase.execute(params),
      ]);

    return { transactionData, monthlyData, sankeyData, balanceSheetData };
  },
  ["top-page-data"],
  { revalidate: 60 },
);

この構造のメリット：

責務の分離: 各usecaseは単一の責務に集中

並列実行: 複数のデータ取得を効率的に処理

テスト容易性: 依存注入により、モックを使ったテストが簡単

再利用性: usecaseは他のページからも呼び出せる

依存性逆転の原則

Repository層にはinterfaceを挟んでいます。これにより、将来的にSupabase以外のデータベースに移行する場合でも、interfaceを実装した新しいRepositoryを作るだけで対応できます。

Next.js 設計: client と server の明確な分離

Next.js の App Router では、サーバーコンポーネントとクライアントコンポーネントが混在します。LLMが混乱しないよう、以下の工夫をしています：

`import "server-only"`の徹底: サーバーサイドでのみ動作すべきファイルには必ずこのimportを追加

ディレクトリの分離: `client/` と `server/` を明確に分ける

相似形の構造: admin と webapp で同じディレクトリ構造を採用し、LLMが迷わないようにする

pnpm によるモノレポ管理

このプロジェクトは、`webapp`（一般公開用）、`admin`（管理画面）、`shared`（共通ロジック）の3つのパッケージで構成されたモノレポです。

LLMがモノレポ全体を参照できることで、以下のメリットがあります：

ドメインオブジェクトを`shared`に配置し、重複を排除

admin と webapp の整合性を保ちやすい

全体を俯瞰した設計判断ができる

工夫 ④: 自動チェックのガードレール

LLMに任せるからこそ、人間がレビューする前に機械的にチェックする仕組みが不可欠です。

コミット時のチェック

commit hook + Biome: コミット時に自動でフォーマットとLintを実行

これにより、フォーマットの乱れや基本的なコーディングミスを防ぐ

CI/CDでのチェック

GitHub Actions: `lint`, `typecheck`, `test` を自動実行

PRがマージされる前に、必ずこれらのチェックをパスする必要がある

重要な処理には手厚くテスト

特に、データの変換やバリデーションなど、バグが致命的な影響を与える部分には、手厚くテストを書いています。LLMにテストコードも書かせることで、実装とテストを同時に整備できます。

工夫 ⑤: スムーズな開発・デバッグ環境

Figma MCP の活用

Claude Codeは、MCP（Model Context Protocol）経由でFigmaのデザインデータを直接読み取ることができます。これにより、デザインからコンポーネントへの実装を半自動化しています。

Vercel の Branch-based Preview

機能ごとにブランチを切り、Vercelの自動プレビュー機能で動作確認を行います。これにより、本番環境を汚さずに、実際の動作を確認できます。

並列作業の効率化

文字列の修正など、LLMに指示するまでもない簡単な変更は、別のAIエージェント（Devin）に投げて並列化することもあります。ただし、このプロジェクトでは主にClaude Codeで統一しています。

まとめ

今回、コードの95%以上をLLMに書かせることができたのは、以下の要因が大きいと考えています：

スクラッチ開発: レガシーコードがなく、モダンな構成を採用できた

明確なルール: CLAUDE.mdによる一貫した開発方針

厳格なアーキテクチャ: クリーンアーキテクチャベースの責務分離

自動化されたガードレール: Lintやテストによる品質担保

逆に言えば、レガシーシステムのリファクタリングや、複雑なドメインロジックが絡む既存システムへの機能追加では、この手法は難しいかもしれません。

しかし、「透明性」という社会的意義を持つプロジェクトを、限られたリソースで短期間に実現できたのは、LLMの力を最大限引き出す工夫があったからこそです。

このツールがOSSとして公開されていることで、他の政党や団体も同じように透明性を確保できます。技術が、政治の透明性を支える時代が来ています。

この記事が、LLMを活用した開発に挑戦する方々の参考になれば幸いです。
